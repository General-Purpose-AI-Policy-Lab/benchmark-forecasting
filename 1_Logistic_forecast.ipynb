{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50118a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from datetime import datetime, date, timedelta\n",
    "from typing import Any, Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c251fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(\n",
    "    dataset: pd.DataFrame,\n",
    "    sigmoid_kind: Literal[\"logistic\", \"harvey\"] = \"logistic\",\n",
    "    n_samples: int = 2000,\n",
    "    n_tune: int = 1000,\n",
    "    top_n: int = 3,\n",
    ") -> az.InferenceData:\n",
    "    \"\"\"Fit a Bayesian model to the dataset using the specified sigmoid function.\n",
    "\n",
    "    If the dataset contains more than one benchmark, a joint model with shared hyperparameters is fitted.\n",
    "\n",
    "    This allows benchmarks to inform each other through common priors on:\n",
    "    - L_mu, L_sigma: (upper) asymptote distribution parameters\n",
    "    - k_mu, k_sigma: growth rate distribution parameters\n",
    "    - xi_base_mu, xi_base_sigma: noise level distribution parameters\n",
    "    - s_mu, s_sigma: skewness distribution parameters\n",
    "\n",
    "    Args:\n",
    "        dataset: A dataset containing benchmark data. It must contain the columns 'score', 'release_date', 'benchmark' and 'lower_bound' of types float, datetime, string, and float respectively.\n",
    "        n_samples: Number of MCMC samples to draw from the posterior distribution.\n",
    "        n_tune: Number of tuning steps for the MCMC sampler.\n",
    "        top_n: Number of top scores to consider when fitting the model. If top_n=1, only the frontier scores are used.\n",
    "\n",
    "    Returns:\n",
    "        An arviz InferenceData object containing the posterior samples.\n",
    "    \"\"\"\n",
    "    # Check validity of the dataset\n",
    "    required_columns_and_types = {\n",
    "        \"score\": pd.api.types.is_float_dtype,\n",
    "        \"release_date\": pd.api.types.is_datetime64_any_dtype,\n",
    "        \"benchmark\": pd.api.types.is_string_dtype,\n",
    "        \"lower_bound\": pd.api.types.is_float_dtype,\n",
    "    }\n",
    "    for column, check_type in required_columns_and_types.items():\n",
    "        if column not in dataset.columns:\n",
    "            raise ValueError(f\"Dataset must contain the column '{column}'.\")\n",
    "        if not check_type(dataset[column]):\n",
    "            raise TypeError(f\"Column '{column}' must be of type {check_type.__name__}.\")\n",
    "        if dataset[column].isnull().any():\n",
    "            raise ValueError(f\"Column '{column}' must not contain null values.\")\n",
    "\n",
    "    # Filter in the top_n frontier scores\n",
    "    dataset = (\n",
    "        dataset.sort_values([\"benchmark\", \"release_date\"])\n",
    "        .assign(\n",
    "            expanding_rank=lambda df: df.groupby(\"benchmark\")[\"score\"]\n",
    "            .expanding()\n",
    "            .rank(ascending=False, method=\"max\")\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        .loc[lambda df: df[\"expanding_rank\"] <= top_n]\n",
    "        .drop(columns=[\"expanding_rank\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Prepare necessary columns for modeling\n",
    "    dataset = dataset.assign(\n",
    "        days=lambda df: (\n",
    "            df[\"release_date\"]\n",
    "            - df.groupby(\"benchmark\")[\"release_date\"].transform(\"min\")\n",
    "        ).dt.days\n",
    "    ).assign(\n",
    "        days_mid=lambda df: (df.groupby(\"benchmark\")[\"days\"].transform(\"max\") / 2.0)\n",
    "    )\n",
    "\n",
    "    # Encode benchmark names as indices for pymc coords\n",
    "    # Use `benchmark_idx` to index the dataset within the model\n",
    "    benchmark_idx, benchmark_names = pd.factorize(dataset[\"benchmark\"], sort=True)\n",
    "    dataset[\"benchmark_idx\"] = benchmark_idx\n",
    "    coords = {\n",
    "        \"benchmark\": benchmark_names,\n",
    "        \"obs\": np.arange(len(dataset)),\n",
    "    }\n",
    "\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # Upper asymptote\n",
    "        L_min = 0.75\n",
    "        L_max = 1.0\n",
    "        L_range = L_max - L_min\n",
    "        L_raw_mu = pm.Beta(\n",
    "            \"L_raw_mu\", mu=(0.96 - L_min) / L_range, sigma=0.02 / L_range\n",
    "        )\n",
    "        L_raw_sigma = pm.HalfNormal(\"L_raw_sigma\", sigma=0.02 / L_range)\n",
    "        L_raw = pm.Beta(\"L_raw\", mu=L_raw_mu, sigma=L_raw_sigma, dims=\"benchmark\")\n",
    "        L = pm.Deterministic(\"L\", L_min + L_range * L_raw, dims=\"benchmark\")\n",
    "\n",
    "        # Lower bound\n",
    "        l = pm.Data(\n",
    "            \"l\",\n",
    "            dataset[\"lower_bound\"].groupby(dataset[\"benchmark_idx\"]).first().values,\n",
    "            dims=\"benchmark\",\n",
    "        )\n",
    "\n",
    "        # Inflection point\n",
    "        days_mid = dataset[\"days_mid\"].groupby(dataset[\"benchmark_idx\"]).first().values\n",
    "        tau = pm.Gumbel(\"tau\", mu=days_mid, beta=365 * 2, dims=\"benchmark\")\n",
    "\n",
    "        # Timestamps\n",
    "        t_obs = pm.Data(\"t_obs\", dataset[\"days\"].values, dims=\"obs\")\n",
    "        idx_obs = pm.Data(\"idx_obs\", dataset[\"benchmark_idx\"].values, dims=\"obs\")\n",
    "\n",
    "        # Growth rate\n",
    "        k_mu = pm.Gamma(\"k_mu\", mu=0.005, sigma=0.002)\n",
    "        k_sigma = pm.HalfNormal(\"k_sigma\", sigma=0.005)\n",
    "        k = pm.Gamma(\"k\", mu=k_mu, sigma=k_sigma, dims=\"benchmark\")\n",
    "\n",
    "        # Mean latent performance\n",
    "        logits = k[idx_obs] * (t_obs - tau[idx_obs])\n",
    "        if sigmoid_kind == \"logistic\":\n",
    "            sigmoid = pm.math.sigmoid(logits)\n",
    "        elif sigmoid_kind == \"harvey\":\n",
    "            alpha_raw_mu = pm.Gamma(\"alpha_raw_mu\", mu=1.5, sigma=0.5)\n",
    "            alpha_raw_sigma = pm.HalfNormal(\"alpha_raw_sigma\", sigma=0.5)\n",
    "            alpha_raw = pm.Gamma(\n",
    "                \"alpha_raw\", mu=alpha_raw_mu, sigma=alpha_raw_sigma, dims=\"benchmark\"\n",
    "            )\n",
    "            alpha = pm.Deterministic(\"alpha\", alpha_raw + 1.0, dims=\"benchmark\")\n",
    "            base = pm.math.maximum(\n",
    "                1 - (1 - alpha[idx_obs]) * pm.math.exp(-logits), 1e-10\n",
    "            )\n",
    "            sigmoid = pm.math.exp(1 / (1 - alpha[idx_obs]) * pm.math.log(base))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported sigmoid type: {sigmoid_kind}\")\n",
    "        mu = l[idx_obs] + (L[idx_obs] - l[idx_obs]) * sigmoid\n",
    "\n",
    "        # Noise\n",
    "        xi_base_mu = pm.Gamma(\"xi_base_mu\", mu=0.05 + top_n / 50, sigma=0.02)\n",
    "        xi_base_sigma = pm.HalfNormal(\"xi_base_sigma\", sigma=0.05)\n",
    "        xi_base = pm.Gamma(\n",
    "            \"xi_base\", mu=xi_base_mu, sigma=xi_base_sigma, dims=\"benchmark\"\n",
    "        )\n",
    "        variance_shape = pm.math.sqrt((mu - l[idx_obs]) * (L[idx_obs] - mu))\n",
    "        max_variance = (L[idx_obs] - l[idx_obs]) / 2.0\n",
    "        noise_factor = variance_shape / pm.math.maximum(max_variance, 1e-10)\n",
    "        xi_0 = 0.01\n",
    "        xi = xi_0 + xi_base[idx_obs] * noise_factor\n",
    "\n",
    "        # Skewness\n",
    "        s_mu = pm.Normal(\"s_mu\", mu=-2 - top_n / 2, sigma=0.5)\n",
    "        s_sigma = pm.HalfNormal(\"s_sigma\", sigma=1)\n",
    "        s = pm.TruncatedNormal(\"s\", mu=s_mu, sigma=s_sigma, upper=0, dims=\"benchmark\")\n",
    "\n",
    "        # Observations\n",
    "        y = pm.SkewNormal(\n",
    "            \"y\",\n",
    "            mu=mu,\n",
    "            sigma=xi,\n",
    "            alpha=s[idx_obs],\n",
    "            observed=dataset[\"score\"].values,\n",
    "            dims=\"obs\",\n",
    "        )\n",
    "\n",
    "        # Sample from the posterior\n",
    "        idata = pm.sample(\n",
    "            n_samples,\n",
    "            tune=n_tune,\n",
    "            return_inferencedata=True,\n",
    "            random_seed=42,\n",
    "            target_accept=0.9,\n",
    "            init=\"adapt_diag\",\n",
    "            progressbar=True,\n",
    "        )\n",
    "\n",
    "    return idata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa23dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [L_raw_mu, L_raw_sigma, L_raw, tau, k_mu, k_sigma, k, alpha_raw_mu, alpha_raw_sigma, alpha_raw, xi_base_mu, xi_base_sigma, xi_base, s_mu, s_sigma, s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d719980b473d4f3ea8d399d7ef44d658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 132 seconds.\n",
      "There were 105 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "dataset = (\n",
    "    pd.read_csv(\"benchmark_data_processed/all_normalized_updated_benchmarks.csv\")\n",
    "    .astype(\n",
    "        {\n",
    "            \"benchmark\": \"string\",\n",
    "            \"release_date\": \"datetime64[ns]\",\n",
    "            \"score\": \"float64\",\n",
    "            \"lower_bound\": \"float64\",\n",
    "        }\n",
    "    )\n",
    "    .dropna(subset=[\"benchmark\", \"release_date\", \"score\", \"lower_bound\"])\n",
    ")\n",
    "idata = fit_model(dataset, top_n=3, sigmoid_kind=\"harvey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7245e72",
   "metadata": {},
   "source": [
    "# PyMC logistic forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast parameters\n",
    "n_samples = 2000\n",
    "n_tune = 1000\n",
    "top_n = 3\n",
    "forecast_days = 1523\n",
    "forecast_type = \"independent\"  # Type of forecast model\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"Images\", exist_ok=True)\n",
    "os.makedirs(\"Fits\", exist_ok=True)\n",
    "\n",
    "\n",
    "def logistic(t, L, k, t0):\n",
    "    \"\"\"\n",
    "    Logistic function: L / (1 + exp(-k * (t - t0)))\n",
    "\n",
    "    Args:\n",
    "        t: time (numeric)\n",
    "        L: asymptote (maximum value)\n",
    "        k: growth rate\n",
    "        t0: inflection point (time at which value = L/2)\n",
    "    \"\"\"\n",
    "    return L / (1 + pm.math.exp(-k * (t - t0)))\n",
    "\n",
    "\n",
    "def extract_frontier_improvements(df_long, top_n=1):\n",
    "    \"\"\"\n",
    "    Extract frontier improvements from benchmark data.\n",
    "\n",
    "    For top_n=1: tracks the absolute best score over time (frontier).\n",
    "    For top_n>1: tracks models that were in top-N at their release date.\n",
    "\n",
    "    Args:\n",
    "        df_long: DataFrame with columns [date, model_id, avg_score]\n",
    "        top_n: number of top models to track\n",
    "\n",
    "    Returns:\n",
    "        List of dicts with keys: date, score, model_id, rank\n",
    "    \"\"\"\n",
    "    df_sorted = df_long.sort_values(\"date\")\n",
    "    frontier_improvements = []\n",
    "\n",
    "    if top_n == 1:\n",
    "        # Original frontier logic (best score over time)\n",
    "        best_score = float(\"-inf\")\n",
    "\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            if row[\"avg_score\"] > best_score:\n",
    "                best_score = row[\"avg_score\"]\n",
    "                frontier_improvements.append(\n",
    "                    {\n",
    "                        \"date\": row[\"date\"],\n",
    "                        \"score\": row[\"avg_score\"],\n",
    "                        \"model_id\": row[\"model_id\"],\n",
    "                        \"rank\": 1,\n",
    "                    }\n",
    "                )\n",
    "    else:\n",
    "        # Track models that were in top-N at their release date\n",
    "        for release_date in df_sorted[\"date\"].unique():\n",
    "            # Models released on this date\n",
    "            released_today = df_sorted[df_sorted[\"date\"] == release_date].copy()\n",
    "\n",
    "            # All scores up to and including today\n",
    "            all_scores_now = df_sorted[df_sorted[\"date\"] <= release_date].copy()\n",
    "\n",
    "            # Get best score per model up to today\n",
    "            best_at_date = (\n",
    "                all_scores_now.groupby(\"model_id\")[\"avg_score\"].max().reset_index()\n",
    "            )\n",
    "\n",
    "            # Get earliest date for each model at their best score\n",
    "            earliest_dates = all_scores_now.loc[\n",
    "                all_scores_now.groupby(\"model_id\")[\"avg_score\"].idxmax()\n",
    "            ][[\"model_id\", \"date\"]].rename(columns={\"date\": \"first_date\"})\n",
    "\n",
    "            best_at_date = best_at_date.merge(earliest_dates, on=\"model_id\")\n",
    "\n",
    "            # Sort: score (desc), date (asc), model_id (asc)\n",
    "            best_at_date = best_at_date.sort_values(\n",
    "                [\"avg_score\", \"first_date\", \"model_id\"], ascending=[False, True, True]\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "            # Assign ranks (same score = same rank)\n",
    "            best_at_date[\"rank\"] = (\n",
    "                best_at_date[\"avg_score\"]\n",
    "                .rank(method=\"dense\", ascending=False)\n",
    "                .astype(int)\n",
    "            )\n",
    "\n",
    "            # For each model released TODAY, check if it's in top-N\n",
    "            for _, row in released_today.iterrows():\n",
    "                model_id = row[\"model_id\"]\n",
    "                model_rank_row = best_at_date[best_at_date[\"model_id\"] == model_id]\n",
    "\n",
    "                if not model_rank_row.empty:\n",
    "                    rank = model_rank_row.iloc[0][\"rank\"]\n",
    "\n",
    "                    if rank <= top_n:\n",
    "                        frontier_improvements.append(\n",
    "                            {\n",
    "                                \"date\": row[\"date\"],\n",
    "                                \"score\": row[\"avg_score\"],\n",
    "                                \"model_id\": model_id,\n",
    "                                \"rank\": rank,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return frontier_improvements\n",
    "\n",
    "\n",
    "def fit_logistic_benchmark(\n",
    "    df_long,\n",
    "    task_name,\n",
    "    n_samples=n_samples,\n",
    "    n_tune=n_tune,\n",
    "    top_n=top_n,\n",
    "    forecast_type=forecast_type,\n",
    "    save_dir=\"Fits\",\n",
    "    lower_bounds_dict=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fit a logistic curve to benchmark data.\n",
    "\n",
    "    Args:\n",
    "        df_long: DataFrame with columns [date, model_id, avg_score]\n",
    "        task_name: name of the benchmark (for plotting)\n",
    "        n_samples: number of MCMC samples\n",
    "        n_tune: number of tuning steps\n",
    "        top_n: number of top models to track (1 = frontier only)\n",
    "        forecast_type: type of forecast model (e.g., \"independent\")\n",
    "        save_dir: directory to save inference data\n",
    "        lower_bounds_dict: dict mapping benchmark names to lower bounds (0-1 scale)\n",
    "\n",
    "    Returns:\n",
    "        idata: InferenceData object with posterior samples\n",
    "        frontier_df: DataFrame with frontier/top-N improvements\n",
    "        model: PyMC model object\n",
    "    \"\"\"\n",
    "    # Extract frontier improvements\n",
    "    frontier_improvements = extract_frontier_improvements(df_long, top_n=top_n)\n",
    "    frontier_df = pd.DataFrame(frontier_improvements)\n",
    "\n",
    "    # Convert dates to numeric (days since first observation)\n",
    "    frontier_df[\"date_dt\"] = pd.to_datetime(frontier_df[\"date\"])\n",
    "    min_date = frontier_df[\"date_dt\"].min()\n",
    "    frontier_df[\"days\"] = (frontier_df[\"date_dt\"] - min_date).dt.days\n",
    "\n",
    "    # Prepare data for PyMC\n",
    "    t_obs = frontier_df[\"days\"].values.astype(float)\n",
    "    y_obs = frontier_df[\"score\"].values.astype(float)\n",
    "\n",
    "    # Get lower bound for this benchmark (default to 0 if not available)\n",
    "    if lower_bounds_dict is not None and task_name in lower_bounds_dict:\n",
    "        lower_bound = lower_bounds_dict[task_name]\n",
    "        # Handle NaN values\n",
    "        if pd.isna(lower_bound):\n",
    "            lower_bound = 0.0\n",
    "            print(f\"  Lower bound for {task_name}: NA (using 0.0)\")\n",
    "        else:\n",
    "            print(f\"  Lower bound for {task_name}: {lower_bound:.1%}\")\n",
    "    else:\n",
    "        lower_bound = 0.0\n",
    "        print(f\"  Lower bound for {task_name}: not found (using 0.0)\")\n",
    "\n",
    "    # Build PyMC model with SHIFTED LOGISTIC\n",
    "    with pm.Model() as model:\n",
    "        # Priors\n",
    "        # L: upper asymptote (Beta prior, must be > L_min)\n",
    "        # Model the range: L ∈ [L_min, 1]\n",
    "        L_min = 0.75\n",
    "        available_range = 1.0 - L_min\n",
    "\n",
    "        # Target upper asymptote around 0.95 in absolute terms\n",
    "        target_L_abs = 0.95\n",
    "\n",
    "        # Mean and sd on the raw (0–1) scale\n",
    "        L_raw_mu = (target_L_abs - L_min) / available_range\n",
    "        L_raw_sigma = 0.03 / available_range\n",
    "\n",
    "        # Upper asymptote (using shifted Beta on raw scale)\n",
    "        L_raw = pm.Beta(\"L_raw\", mu=L_raw_mu, sigma=L_raw_sigma)\n",
    "        L = pm.Deterministic(\"L\", L_min + available_range * L_raw)\n",
    "\n",
    "        # k: growth rate\n",
    "        k = pm.Gamma(\"k\", mu=0.01, sigma=0.008)\n",
    "\n",
    "        # t0: inflection point\n",
    "        t_mid = (t_obs.min() + t_obs.max()) / 2\n",
    "        t0 = pm.Gumbel(\"t0\", mu=t_mid, beta=365 * 2)\n",
    "\n",
    "        # Expected value: SHIFTED LOGISTIC\n",
    "        # y = lower_bound + (L - lower_bound) / (1 + exp(-k * (t - t0)))\n",
    "        logistic_01 = 1.0 / (1 + pm.math.exp(-k * (t_obs - t0)))\n",
    "        mu = lower_bound + (L - lower_bound) * logistic_01\n",
    "\n",
    "        # Heteroskedastic noise model: Beta-like pattern\n",
    "        # Base noise level (more noise for higher top_n)\n",
    "        xi_base = pm.Gamma(\"xi_base\", mu=0.05 + top_n / 100, sigma=0.035 + top_n / 200)\n",
    "\n",
    "        # Beta-like variance pattern: √((μ - lower_bound) × (L - μ))\n",
    "        # This accounts for the shifted range [lower_bound, L]\n",
    "        variance_shape = pm.math.sqrt((mu - lower_bound) * (L - mu))\n",
    "\n",
    "        # Normalized noise factor (peaks at 1.0 at inflection point)\n",
    "        # Maximum variance is at midpoint: (L - lower_bound) / 2\n",
    "        max_variance = (L - lower_bound) / 2.0\n",
    "        noise_factor = variance_shape / pm.math.maximum(\n",
    "            max_variance, 1e-10\n",
    "        )  # Avoid division by zero\n",
    "\n",
    "        # Skewness parameter (more asymmetry for higher top_n)\n",
    "        s = pm.TruncatedNormal(\n",
    "            \"s\", mu=-1.5 - top_n / 2, sigma=0.375 + top_n / 8, upper=0\n",
    "        )\n",
    "\n",
    "        # Likelihood\n",
    "        y = pm.SkewNormal(\n",
    "            \"y\", mu=mu, sigma=0.01 + xi_base * noise_factor, alpha=s, observed=y_obs\n",
    "        )\n",
    "\n",
    "        # Sample\n",
    "        idata = pm.sample(\n",
    "            n_samples,\n",
    "            tune=n_tune,\n",
    "            return_inferencedata=True,\n",
    "            random_seed=42,\n",
    "            target_accept=0.9,\n",
    "            progressbar=False,\n",
    "        )\n",
    "\n",
    "    # Save results\n",
    "    safe_task_name = task_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "\n",
    "    # Save inference data (NetCDF format - can be loaded with az.from_netcdf())\n",
    "    idata_path = os.path.join(\n",
    "        save_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_idata.nc\"\n",
    "    )\n",
    "    if os.path.exists(\n",
    "        idata_path\n",
    "    ):  # Remove existing file to ensure correct case on macOS\n",
    "        os.remove(idata_path)\n",
    "    idata.to_netcdf(idata_path)\n",
    "    print(f\"Saved inference data to: {idata_path}\")\n",
    "\n",
    "    # Save frontier data (CSV)\n",
    "    frontier_csv_path = os.path.join(\n",
    "        save_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_frontier.csv\"\n",
    "    )\n",
    "    if os.path.exists(frontier_csv_path):\n",
    "        os.remove(frontier_csv_path)\n",
    "    frontier_df.to_csv(frontier_csv_path, index=False)\n",
    "    print(f\"Saved frontier data to: {frontier_csv_path}\")\n",
    "\n",
    "    # Save metadata object (pickle) - excludes model which can't be pickled\n",
    "    metadata = {\n",
    "        \"task_name\": task_name,\n",
    "        \"top_n\": top_n,\n",
    "        \"forecast_type\": forecast_type,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"n_tune\": n_tune,\n",
    "        \"idata_path\": idata_path,\n",
    "        \"frontier_csv_path\": frontier_csv_path,\n",
    "        \"heteroskedastic\": True,\n",
    "        \"noise_model\": \"beta_like\",\n",
    "        \"lower_bound\": lower_bound,\n",
    "    }\n",
    "    metadata_path = os.path.join(\n",
    "        save_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_metadata.pkl\"\n",
    "    )\n",
    "    if os.path.exists(metadata_path):\n",
    "        os.remove(metadata_path)\n",
    "    with open(metadata_path, \"wb\") as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(f\"Saved metadata to: {metadata_path}\")\n",
    "\n",
    "    return idata, frontier_df, model\n",
    "\n",
    "\n",
    "def plot_logistic_fit(\n",
    "    idata,\n",
    "    frontier_df,\n",
    "    task_name,\n",
    "    forecast_days=forecast_days,\n",
    "    top_n=top_n,\n",
    "    forecast_type=forecast_type,\n",
    "    save_dir=\"Images\",\n",
    "    lower_bound=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the logistic fit with uncertainty bands.\n",
    "\n",
    "    Args:\n",
    "        idata: InferenceData from PyMC sampling\n",
    "        frontier_df: DataFrame with frontier data and 'days' column\n",
    "        task_name: name of the benchmark\n",
    "        forecast_days: number of days to forecast beyond last observation\n",
    "        top_n: number of top models tracked (for title)\n",
    "        forecast_type: type of forecast model (for filename)\n",
    "        save_dir: directory to save plots\n",
    "        lower_bound: lower asymptote (random chance baseline)\n",
    "    \"\"\"\n",
    "    # Extract posterior samples\n",
    "    posterior = idata.posterior\n",
    "    L_samples = posterior[\"L\"].values.flatten()\n",
    "    k_samples = posterior[\"k\"].values.flatten()\n",
    "    t0_samples = posterior[\"t0\"].values.flatten()\n",
    "    xi_base_samples = posterior[\"xi_base\"].values.flatten()\n",
    "    s_samples = posterior[\"s\"].values.flatten()\n",
    "\n",
    "    # Prepare time grid for plotting (observed + forecast)\n",
    "    t_obs = frontier_df[\"days\"].values\n",
    "    t_min = t_obs.min()\n",
    "    t_max = t_obs.max() + forecast_days\n",
    "    t_grid = np.linspace(t_min, t_max, 200)\n",
    "\n",
    "    # Calculate predictions for each posterior sample (SHIFTED logistic curve)\n",
    "    n_samples = len(L_samples)\n",
    "    predictions = np.zeros((n_samples, len(t_grid)))\n",
    "    xi_grid = np.zeros((n_samples, len(t_grid)))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Shifted logistic curve\n",
    "        logistic_01 = 1.0 / (1 + np.exp(-k_samples[i] * (t_grid - t0_samples[i])))\n",
    "        mu_i = lower_bound + (L_samples[i] - lower_bound) * logistic_01\n",
    "        predictions[i] = mu_i\n",
    "\n",
    "        # Recalculate heteroskedastic sigma for shifted range\n",
    "        variance_shape = np.sqrt((mu_i - lower_bound) * (L_samples[i] - mu_i))\n",
    "        max_variance = (L_samples[i] - lower_bound) / 2.0\n",
    "        noise_factor = variance_shape / np.maximum(\n",
    "            max_variance, 1e-10\n",
    "        )  # Avoid division by zero\n",
    "        xi_grid[i] = 0.01 + xi_base_samples[i] * noise_factor\n",
    "\n",
    "    # Calculate percentiles for logistic curve\n",
    "    median_pred = np.percentile(predictions, 50, axis=0)\n",
    "    lower_50_logistic = np.percentile(predictions, 25, axis=0)\n",
    "    upper_50_logistic = np.percentile(predictions, 75, axis=0)\n",
    "    lower_95_logistic = np.percentile(predictions, 2.5, axis=0)\n",
    "    upper_95_logistic = np.percentile(predictions, 97.5, axis=0)\n",
    "\n",
    "    # Prediction intervals with observation noise (vectorized)\n",
    "    from scipy.stats import skewnorm\n",
    "\n",
    "    lower_95_sampling = np.zeros(len(t_grid))\n",
    "    upper_95_sampling = np.zeros(len(t_grid))\n",
    "\n",
    "    for j in range(len(t_grid)):\n",
    "        # Vectorized: one draw per posterior sample\n",
    "        samples = skewnorm.rvs(s_samples, loc=predictions[:, j], scale=xi_grid[:, j])\n",
    "        samples = np.clip(samples, 0, 1)\n",
    "        lower_95_sampling[j] = np.percentile(samples, 2.5)\n",
    "        upper_95_sampling[j] = np.percentile(samples, 97.5)\n",
    "\n",
    "    # Convert days back to dates for x-axis\n",
    "    min_date = frontier_df[\"date\"].min()\n",
    "    dates_grid = [min_date + timedelta(days=int(d)) for d in t_grid]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Add horizontal line for lower bound if > 0\n",
    "    if lower_bound > 0.01:\n",
    "        ax.axhline(\n",
    "            lower_bound,\n",
    "            color=\"gray\",\n",
    "            linestyle=\":\",\n",
    "            alpha=0.5,\n",
    "            linewidth=1.5,\n",
    "            label=f\"Random chance ({lower_bound:.1%})\",\n",
    "        )\n",
    "\n",
    "    # Predicted sampling intervals (wider, includes observation noise)\n",
    "    ax.fill_between(\n",
    "        dates_grid,\n",
    "        lower_95_sampling,\n",
    "        upper_95_sampling,\n",
    "        alpha=0.1,\n",
    "        color=\"#F18F01\",\n",
    "        label=\"95% prediction interval\",\n",
    "    )\n",
    "\n",
    "    # Logistic uncertainty bands (narrower, just curve uncertainty)\n",
    "    ax.fill_between(\n",
    "        dates_grid,\n",
    "        lower_95_logistic,\n",
    "        upper_95_logistic,\n",
    "        alpha=0.2,\n",
    "        color=\"#2E86AB\",\n",
    "        label=\"95% CI (logistic)\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        dates_grid,\n",
    "        lower_50_logistic,\n",
    "        upper_50_logistic,\n",
    "        alpha=0.3,\n",
    "        color=\"#2E86AB\",\n",
    "        label=\"50% CI (logistic)\",\n",
    "    )\n",
    "\n",
    "    # Median prediction\n",
    "    ax.plot(\n",
    "        dates_grid,\n",
    "        median_pred,\n",
    "        \"-\",\n",
    "        linewidth=2,\n",
    "        color=\"#2E86AB\",\n",
    "        label=\"Median prediction\",\n",
    "    )\n",
    "\n",
    "    # Observed points - color by rank if top_n > 1\n",
    "    if top_n == 1:\n",
    "        ax.plot(\n",
    "            frontier_df[\"date\"],\n",
    "            frontier_df[\"score\"],\n",
    "            \"o\",\n",
    "            markersize=8,\n",
    "            color=\"#A23B72\",\n",
    "            label=\"Observed frontier\",\n",
    "            zorder=10,\n",
    "        )\n",
    "    else:\n",
    "        # Plot different ranks with different colors/sizes\n",
    "        colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, top_n))\n",
    "        for rank in range(1, top_n + 1):\n",
    "            rank_data = frontier_df[frontier_df[\"rank\"] == rank]\n",
    "            if not rank_data.empty:\n",
    "                ax.plot(\n",
    "                    rank_data[\"date\"],\n",
    "                    rank_data[\"score\"],\n",
    "                    \"o\",\n",
    "                    markersize=10 - (rank - 1) * 1.0,\n",
    "                    color=colors[rank - 1],\n",
    "                    label=f\"Top-{rank} at release\",\n",
    "                    alpha=0.8,\n",
    "                    zorder=10 - rank,\n",
    "                )\n",
    "\n",
    "    # Vertical line at last observation\n",
    "    last_date = frontier_df[\"date\"].max()\n",
    "    ax.axvline(last_date, color=\"gray\", linestyle=\"--\", alpha=0.5, linewidth=1)\n",
    "    ax.text(\n",
    "        last_date,\n",
    "        ax.get_ylim()[0] + 0.05,\n",
    "        \"Last obs\",\n",
    "        rotation=90,\n",
    "        verticalalignment=\"bottom\",\n",
    "        fontsize=9,\n",
    "        color=\"gray\",\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    title_suffix = \" (Frontier)\" if top_n == 1 else f\" (Top-{top_n} at release)\"\n",
    "    ax.set_title(\n",
    "        f\"Logistic Growth Forecast: {task_name}{title_suffix}\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"lower right\", fontsize=9)\n",
    "\n",
    "    # Set y-axis limits based on lower bound\n",
    "    # y_min = max(0, lower_bound - 0.05)\n",
    "    # ax.set_ylim(y_min, 1.05)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "    # Format x-axis\n",
    "    import matplotlib.dates as mdates\n",
    "\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    safe_task_name = task_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "    plot_path = os.path.join(\n",
    "        save_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_forecast.png\"\n",
    "    )\n",
    "    if os.path.exists(\n",
    "        plot_path\n",
    "    ):  # Remove existing file to ensure correct case on macOS\n",
    "        os.remove(plot_path)\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved plot to: {plot_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    title_text = (\n",
    "        f\"FORECAST SUMMARY: {task_name} (Top-{top_n} at release)\"\n",
    "        if top_n > 1\n",
    "        else f\"FORECAST SUMMARY: {task_name} (Frontier)\"\n",
    "    )\n",
    "    print(title_text)\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Data points: {len(frontier_df)}\")\n",
    "    print(f\"Unique models: {frontier_df['model_id'].nunique()}\")\n",
    "    print(f\"Lower asymptote (random chance): {lower_bound:.3f}\")\n",
    "    print(f\"Current best score: {frontier_df['score'].max():.3f}\")\n",
    "    print(\n",
    "        f\"Predicted upper asymptote (L): {np.median(L_samples):.3f} [{np.percentile(L_samples, 2.5):.3f}, {np.percentile(L_samples, 97.5):.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Growth rate (k): {np.median(k_samples):.4f} [{np.percentile(k_samples, 2.5):.4f}, {np.percentile(k_samples, 97.5):.4f}]\"\n",
    "    )\n",
    "    print(f\"Inflection point (t0): {np.median(t0_samples):.0f} days\")\n",
    "\n",
    "    # Time to reach milestones\n",
    "    current_score = frontier_df[\"score\"].max()\n",
    "    current_days = frontier_df[\"days\"].max()\n",
    "\n",
    "    for target in [0.9, 0.95, 0.99]:\n",
    "        if target > current_score:\n",
    "            # For each posterior sample, calculate when target is reached\n",
    "            days_to_target = []\n",
    "            for i in range(n_samples):\n",
    "                # Solve: target =  L / (1 + exp(-k * (t - t0)))\n",
    "                # target / L = 1 / (1 + exp(-k * (t - t0)))\n",
    "                # t = t0 - log(L/target - 1) / k\n",
    "                ratio = target / L_samples[i]\n",
    "                if 0 < ratio < 1:  # valid range\n",
    "                    t_target = t0_samples[i] - np.log(1 / ratio - 1) / k_samples[i]\n",
    "                    days_from_now = t_target - current_days\n",
    "                    if days_from_now > 0:\n",
    "                        days_to_target.append(days_from_now)\n",
    "\n",
    "            if days_to_target:\n",
    "                median_days = np.median(days_to_target)\n",
    "                lower_days = np.percentile(days_to_target, 2.5)\n",
    "                upper_days = np.percentile(days_to_target, 97.5)\n",
    "                target_date = last_date + timedelta(days=int(median_days))\n",
    "                print(\n",
    "                    f\"\\nTime to reach {target:.0%}: {median_days / 365:.1f} years \"\n",
    "                    + f\"[{lower_days / 365:.1f}, {upper_days / 365:.1f}] (ETA: {target_date.strftime('%Y-%m')})\"\n",
    "                )\n",
    "\n",
    "\n",
    "def load_fit(task_name, forecast_type=forecast_type, top_n=top_n, load_dir=\"Fits\"):\n",
    "    \"\"\"\n",
    "    Load a previously saved fit object.\n",
    "\n",
    "    Args:\n",
    "        task_name: name of the benchmark\n",
    "        forecast_type: type of forecast model\n",
    "        top_n: number of top models\n",
    "        load_dir: directory containing saved fits\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing idata, frontier_df, and metadata\n",
    "    \"\"\"\n",
    "    safe_task_name = task_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "\n",
    "    # Load inference data\n",
    "    idata_path = os.path.join(\n",
    "        load_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_idata.nc\"\n",
    "    )\n",
    "    idata = az.from_netcdf(idata_path)\n",
    "\n",
    "    # Load frontier data\n",
    "    frontier_csv_path = os.path.join(\n",
    "        load_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_frontier.csv\"\n",
    "    )\n",
    "    frontier_df = pd.read_csv(frontier_csv_path)\n",
    "\n",
    "    # Convert date column back to date objects\n",
    "    frontier_df[\"date\"] = pd.to_datetime(frontier_df[\"date\"]).dt.date\n",
    "    if \"date_dt\" in frontier_df.columns:\n",
    "        frontier_df[\"date_dt\"] = pd.to_datetime(frontier_df[\"date_dt\"])\n",
    "\n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(\n",
    "        load_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_metadata.pkl\"\n",
    "    )\n",
    "    with open(metadata_path, \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "\n",
    "    print(f\"Loaded fit for: {task_name}\")\n",
    "    print(f\"  - Inference data: {idata_path}\")\n",
    "    print(f\"  - Frontier data: {frontier_csv_path}\")\n",
    "    print(f\"  - Metadata: {metadata_path}\")\n",
    "\n",
    "    fit_object = {\n",
    "        \"idata\": idata,\n",
    "        \"frontier_df\": frontier_df,\n",
    "        \"metadata\": metadata,\n",
    "        \"task_name\": task_name,\n",
    "        \"top_n\": top_n,\n",
    "        \"forecast_type\": forecast_type,\n",
    "    }\n",
    "\n",
    "    return fit_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b5c8c",
   "metadata": {},
   "source": [
    "## Independent forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57e26a",
   "metadata": {},
   "source": [
    "### Internal Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fit for all internal benchmarks\n",
    "internal_matrices, external_matrices = load_all_benchmark_matrices()\n",
    "\n",
    "print(f\"Found {len(internal_matrices)} internal benchmarks\")\n",
    "print(f\"Found {len(external_matrices)} external benchmarks\")\n",
    "\n",
    "# Fit logistic models to internal benchmarks\n",
    "results = {}\n",
    "\n",
    "for task_name, data in internal_matrices.items():\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Fitting: {task_name}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    df_long = data[\"df_long\"]\n",
    "\n",
    "    if len(df_long) < 3:\n",
    "        print(f\"Skipping {task_name}: insufficient data ({len(df_long)} observations)\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        idata, frontier_df, model = fit_logistic_benchmark(\n",
    "            df_long, task_name, lower_bounds_dict=lower_bounds_dict\n",
    "        )\n",
    "\n",
    "        # Get lower bound for plotting\n",
    "        lower_bound = 0.0\n",
    "        if lower_bounds_dict and task_name in lower_bounds_dict:\n",
    "            lb = lower_bounds_dict[task_name]\n",
    "            if not pd.isna(lb):\n",
    "                lower_bound = lb\n",
    "\n",
    "        results[task_name] = {\n",
    "            \"idata\": idata,\n",
    "            \"frontier_df\": frontier_df,\n",
    "            \"model\": model,\n",
    "        }\n",
    "\n",
    "        # Plot\n",
    "        plot_logistic_fit(idata, frontier_df, task_name, lower_bound=lower_bound)\n",
    "\n",
    "        # Print diagnostics\n",
    "        print(\"\\nMCMC Diagnostics:\")\n",
    "        print(az.summary(idata, var_names=[\"L\", \"k\", \"t0\", \"xi_base\", \"s\"]))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting {task_name}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d8aa0",
   "metadata": {},
   "source": [
    "### External benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name, data in external_matrices.items():\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Fitting: {task_name}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    df_long = data[\"df_long\"]\n",
    "\n",
    "    if len(df_long) < 3:\n",
    "        print(f\"Skipping {task_name}: insufficient data ({len(df_long)} observations)\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        idata, frontier_df, model = fit_logistic_benchmark(\n",
    "            df_long, task_name, lower_bounds_dict=lower_bounds_dict\n",
    "        )\n",
    "\n",
    "        # Get lower bound for plotting\n",
    "        lower_bound = 0.0\n",
    "        if lower_bounds_dict and task_name in lower_bounds_dict:\n",
    "            lb = lower_bounds_dict[task_name]\n",
    "            if not pd.isna(lb):\n",
    "                lower_bound = lb\n",
    "\n",
    "        results[task_name] = {\n",
    "            \"idata\": idata,\n",
    "            \"frontier_df\": frontier_df,\n",
    "            \"model\": model,\n",
    "        }\n",
    "\n",
    "        # Plot\n",
    "        plot_logistic_fit(idata, frontier_df, task_name, lower_bound=lower_bound)\n",
    "\n",
    "        # Print diagnostics\n",
    "        print(\"\\nMCMC Diagnostics:\")\n",
    "        print(az.summary(idata, var_names=[\"L\", \"k\", \"t0\", \"xi_base\", \"s\"]))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting {task_name}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"Successfully fit {len(results)} / {len(external_matrices)} benchmarks\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0adf9",
   "metadata": {},
   "source": [
    "## Joint hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ce18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# JOINT HYPERPARAMETER MODEL\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def fit_logistic_joint_hyperparameters(\n",
    "    benchmark_dict,\n",
    "    n_samples=2000,\n",
    "    n_tune=1000,\n",
    "    top_n=3,\n",
    "    forecast_type=\"joint_hyperparameters\",\n",
    "    save_dir=\"Fits\",\n",
    "    lower_bounds_dict=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fit logistic curves to multiple benchmarks with shared hyperparameters.\n",
    "\n",
    "    This allows benchmarks to inform each other through common priors on:\n",
    "    - L_mu, L_sigma: asymptote distribution parameters\n",
    "    - k_mu, k_sigma: growth rate distribution parameters\n",
    "    - xi_base_mu, xi_base_sigma: noise level distribution parameters\n",
    "    - s_mu, s_sigma: skewness distribution parameters\n",
    "\n",
    "    Args:\n",
    "        benchmark_dict: dict of {task_name: df_long} for multiple benchmarks\n",
    "        n_samples: number of MCMC samples\n",
    "        n_tune: number of tuning steps\n",
    "        top_n: number of top models to track (fixed, not learned)\n",
    "        forecast_type: type of forecast model\n",
    "        save_dir: directory to save inference data\n",
    "        lower_bounds_dict: dict mapping benchmark names to lower bounds (0-1 scale)\n",
    "\n",
    "    Returns:\n",
    "        idata: InferenceData with posterior samples for all benchmarks\n",
    "        frontier_dfs: dict of {task_name: frontier_df}\n",
    "        model: PyMC model object\n",
    "    \"\"\"\n",
    "    # Prepare data for all benchmarks\n",
    "    task_names = []\n",
    "    all_t_obs = []\n",
    "    all_y_obs = []\n",
    "    all_lower_bounds = []\n",
    "    frontier_dfs = {}\n",
    "\n",
    "    for task_idx, (task_name, df_long) in enumerate(benchmark_dict.items()):\n",
    "        # Extract frontier (same logic as independent model)\n",
    "        frontier_improvements = extract_frontier_improvements(df_long, top_n=top_n)\n",
    "\n",
    "        frontier_df = pd.DataFrame(frontier_improvements)\n",
    "        frontier_df[\"date_dt\"] = pd.to_datetime(frontier_df[\"date\"])\n",
    "        min_date = frontier_df[\"date_dt\"].min()\n",
    "        frontier_df[\"days\"] = (frontier_df[\"date_dt\"] - min_date).dt.days\n",
    "\n",
    "        # Get lower bound for this benchmark\n",
    "        if lower_bounds_dict is not None and task_name in lower_bounds_dict:\n",
    "            lower_bound = lower_bounds_dict[task_name]\n",
    "            if pd.isna(lower_bound):\n",
    "                lower_bound = 0.0\n",
    "                print(f\"  Lower bound for {task_name}: NA (using 0.0)\")\n",
    "            else:\n",
    "                print(f\"  Lower bound for {task_name}: {lower_bound:.1%}\")\n",
    "        else:\n",
    "            lower_bound = 0.0\n",
    "            print(f\"  Lower bound for {task_name}: not found (using 0.0)\")\n",
    "\n",
    "        # Store frontier data\n",
    "        frontier_dfs[task_name] = frontier_df\n",
    "        task_names.append(task_name)\n",
    "        all_lower_bounds.append(lower_bound)\n",
    "\n",
    "        # Prepare PyMC data\n",
    "        t_obs = frontier_df[\"days\"].values.astype(float)\n",
    "        y_obs = frontier_df[\"score\"].values.astype(float)\n",
    "\n",
    "        all_t_obs.append(t_obs)\n",
    "        all_y_obs.append(y_obs)\n",
    "\n",
    "    n_tasks = len(task_names)\n",
    "    all_lower_bounds = np.array(all_lower_bounds)\n",
    "\n",
    "    # ========================================================================\n",
    "    # VECTORIZATION: Concatenate all observations with task indices\n",
    "    # ========================================================================\n",
    "\n",
    "    # Create task indices for each observation\n",
    "    task_indices = []\n",
    "    for task_idx in range(n_tasks):\n",
    "        task_indices.extend([task_idx] * len(all_t_obs[task_idx]))\n",
    "    task_indices = np.array(task_indices, dtype=np.int32)\n",
    "\n",
    "    # Concatenate all observations\n",
    "    t_obs_all = np.concatenate(all_t_obs)\n",
    "    y_obs_all = np.concatenate(all_y_obs)\n",
    "    n_obs_total = len(t_obs_all)\n",
    "\n",
    "    # Lower bounds for each observation (indexed by task)\n",
    "    lower_bounds_per_obs = all_lower_bounds[task_indices]\n",
    "\n",
    "    # Calculate t_mids for each task\n",
    "    t_mids = np.array(\n",
    "        [(all_t_obs[i].min() + all_t_obs[i].max()) / 2 for i in range(n_tasks)]\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"VECTORIZED MODEL SETUP\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Number of tasks: {n_tasks}\")\n",
    "    print(f\"Total observations: {n_obs_total}\")\n",
    "    print(f\"Observations per task: {[len(t) for t in all_t_obs]}\")\n",
    "\n",
    "    # Build joint hierarchical model with SHIFTED LOGISTIC (VECTORIZED)\n",
    "    with pm.Model() as model:\n",
    "        # ====================================================================\n",
    "        # HYPERPRIORS (shared across all benchmarks)\n",
    "        # ====================================================================\n",
    "\n",
    "        # Asymptote (L) hyperparameters (defined on raw 0–1 scale, then shifted)\n",
    "        L_min = 0.75  # Minimum allowed asymptote (absolute value)\n",
    "        available_range = 1.0 - L_min\n",
    "\n",
    "        # Hyperprior for the population mean and sd of L on the raw scale\n",
    "        L_raw_mu = pm.Beta(\n",
    "            \"L_raw_mu\",\n",
    "            mu=(0.96 - L_min)\n",
    "            / available_range,  # centers L_mu around 0.96 on absolute scale\n",
    "            sigma=0.02 / available_range,  # corresponding sd on raw scale\n",
    "        )\n",
    "        L_raw_sigma = pm.HalfNormal(\"L_raw_sigma\", sigma=0.03 / available_range)\n",
    "\n",
    "        # Implied absolute-scale hyperparameters (for diagnostics)\n",
    "        L_mu = pm.Deterministic(\"L_mu\", L_min + available_range * L_raw_mu)\n",
    "        L_sigma = pm.Deterministic(\"L_sigma\", available_range * L_raw_sigma)\n",
    "\n",
    "        # Growth rate (k) hyperparameters\n",
    "        k_mu = pm.Gamma(\"k_mu\", mu=0.005, sigma=0.002)\n",
    "        k_sigma = pm.HalfNormal(\"k_sigma\", sigma=0.005)\n",
    "\n",
    "        # Base noise (xi_base) hyperparameters\n",
    "        xi_base_mu = pm.Gamma(\"xi_base_mu\", mu=0.05 + top_n / 50, sigma=0.02)\n",
    "        xi_base_sigma = pm.HalfNormal(\"xi_base_sigma\", sigma=0.05)\n",
    "\n",
    "        # Skewness (s) hyperparameters\n",
    "        s_mu = pm.Normal(\"s_mu\", mu=-2 - top_n / 2, sigma=0.5)\n",
    "        s_sigma = pm.HalfNormal(\"s_sigma\", sigma=1)\n",
    "\n",
    "        # ====================================================================\n",
    "        # TASK-SPECIFIC PARAMETERS (informed by hyperpriors)\n",
    "        # ====================================================================\n",
    "\n",
    "        # Task-specific upper asymptotes (using shifted Beta on raw scale)\n",
    "        L_raw = pm.Beta(\"L_raw\", mu=L_raw_mu, sigma=L_raw_sigma, shape=n_tasks)\n",
    "        L = pm.Deterministic(\"L\", L_min + available_range * L_raw)\n",
    "\n",
    "        # Task-specific growth rates\n",
    "        k = pm.Gamma(\"k\", mu=k_mu, sigma=k_sigma, shape=n_tasks)\n",
    "\n",
    "        # Task-specific inflection points (t0)\n",
    "        t0 = pm.Gumbel(\"t0\", mu=t_mids, beta=365 * 2, shape=n_tasks)\n",
    "\n",
    "        # Task-specific base noise\n",
    "        xi_base = pm.Gamma(\"xi_base\", mu=xi_base_mu, sigma=xi_base_sigma, shape=n_tasks)\n",
    "\n",
    "        # Task-specific skewness\n",
    "        s = pm.TruncatedNormal(\"s\", mu=s_mu, sigma=s_sigma, upper=0, shape=n_tasks)\n",
    "\n",
    "        # ====================================================================\n",
    "        # VECTORIZED LIKELIHOOD\n",
    "        # ====================================================================\n",
    "\n",
    "        # Index task-specific parameters by observation\n",
    "        L_obs = L[task_indices]\n",
    "        k_obs = k[task_indices]\n",
    "        t0_obs = t0[task_indices]\n",
    "        xi_base_obs = xi_base[task_indices]\n",
    "        s_obs = s[task_indices]\n",
    "        lower_bounds_obs = pm.math.constant(lower_bounds_per_obs)\n",
    "\n",
    "        # Shifted logistic curve (vectorized over all observations)\n",
    "        logistic_01 = 1.0 / (1 + pm.math.exp(-k_obs * (t_obs_all - t0_obs)))\n",
    "        mu_obs = lower_bounds_obs + (L_obs - lower_bounds_obs) * logistic_01\n",
    "\n",
    "        # Heteroskedastic noise (Beta-like pattern for shifted range)\n",
    "        variance_shape = pm.math.sqrt((mu_obs - lower_bounds_obs) * (L_obs - mu_obs))\n",
    "        max_variance = (L_obs - lower_bounds_obs) / 2.0\n",
    "        noise_factor = variance_shape / pm.math.maximum(\n",
    "            max_variance, 1e-10\n",
    "        )  # Avoid division by zero\n",
    "        xi = 0.01 + xi_base_obs * noise_factor\n",
    "\n",
    "        # Single vectorized likelihood for ALL observations\n",
    "        y = pm.SkewNormal(\"y\", mu=mu_obs, sigma=xi, alpha=s_obs, observed=y_obs_all)\n",
    "\n",
    "        # ====================================================================\n",
    "        # SAMPLING\n",
    "        # ====================================================================\n",
    "\n",
    "        print(f\"Fitting vectorized joint model with {n_tasks} benchmarks...\")\n",
    "        print(f\"Total observations: {n_obs_total}\")\n",
    "\n",
    "        idata = pm.sample(\n",
    "            n_samples,\n",
    "            tune=n_tune,\n",
    "            return_inferencedata=True,\n",
    "            random_seed=42,\n",
    "            target_accept=0.9,\n",
    "            init=\"adapt_diag\",\n",
    "            progressbar=True,\n",
    "        )\n",
    "\n",
    "    # ====================================================================\n",
    "    # SAVE RESULTS\n",
    "    # ====================================================================\n",
    "\n",
    "    # Save joint inference data\n",
    "    idata_path = os.path.join(save_dir, f\"joint_{forecast_type}_top{top_n}_idata.nc\")\n",
    "    idata.to_netcdf(idata_path)\n",
    "    print(f\"\\nSaved joint inference data to: {idata_path}\")\n",
    "\n",
    "    # Save individual frontier CSVs\n",
    "    for task_name, frontier_df in frontier_dfs.items():\n",
    "        safe_task_name = task_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "        frontier_csv_path = os.path.join(\n",
    "            save_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_frontier.csv\"\n",
    "        )\n",
    "        if os.path.exists(frontier_csv_path):\n",
    "            os.remove(frontier_csv_path)\n",
    "        frontier_df.to_csv(frontier_csv_path, index=False)\n",
    "\n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        \"task_names\": task_names,\n",
    "        \"n_tasks\": n_tasks,\n",
    "        \"top_n\": top_n,\n",
    "        \"forecast_type\": forecast_type,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"n_tune\": n_tune,\n",
    "        \"idata_path\": idata_path,\n",
    "        \"heteroskedastic\": True,\n",
    "        \"noise_model\": \"beta_like\",\n",
    "        \"hierarchical\": True,\n",
    "        \"vectorized\": True,\n",
    "        \"lower_bounds\": all_lower_bounds.tolist(),\n",
    "    }\n",
    "    metadata_path = os.path.join(\n",
    "        save_dir, f\"joint_{forecast_type}_top{top_n}_metadata.pkl\"\n",
    "    )\n",
    "    if os.path.exists(metadata_path):\n",
    "        os.remove(metadata_path)\n",
    "    with open(metadata_path, \"wb\") as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(f\"Saved metadata to: {metadata_path}\")\n",
    "\n",
    "    return idata, frontier_dfs, model\n",
    "\n",
    "\n",
    "def plot_logistic_fit_from_joint(\n",
    "    idata,\n",
    "    frontier_df,\n",
    "    task_name,\n",
    "    task_idx,\n",
    "    forecast_days=1523,\n",
    "    top_n=3,\n",
    "    forecast_type=\"joint_hyperparameters\",\n",
    "    save_dir=\"Images\",\n",
    "    lower_bound=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot forecast for a single task from joint model fit.\n",
    "\n",
    "    Args:\n",
    "        idata: InferenceData from joint model\n",
    "        frontier_df: DataFrame with frontier data for this task\n",
    "        task_name: name of the benchmark\n",
    "        task_idx: index of this task in the joint model\n",
    "        forecast_days: number of days to forecast\n",
    "        top_n: number of top models tracked\n",
    "        forecast_type: type of forecast model\n",
    "        save_dir: directory to save plots\n",
    "        lower_bound: lower asymptote (random chance baseline)\n",
    "    \"\"\"\n",
    "    # Extract posterior samples for THIS task\n",
    "    posterior = idata.posterior\n",
    "    L_samples = posterior[\"L\"].sel(L_dim_0=task_idx).values.flatten()\n",
    "    k_samples = posterior[\"k\"].sel(k_dim_0=task_idx).values.flatten()\n",
    "    t0_samples = posterior[\"t0\"].sel(t0_dim_0=task_idx).values.flatten()\n",
    "    xi_base_samples = posterior[\"xi_base\"].sel(xi_base_dim_0=task_idx).values.flatten()\n",
    "    s_samples = posterior[\"s\"].sel(s_dim_0=task_idx).values.flatten()\n",
    "\n",
    "    # Time grid\n",
    "    t_obs = frontier_df[\"days\"].values\n",
    "    t_min = t_obs.min()\n",
    "    t_max = t_obs.max() + forecast_days\n",
    "    t_grid = np.linspace(t_min, t_max, 200)\n",
    "\n",
    "    n_samples = len(L_samples)\n",
    "    predictions = np.zeros((n_samples, len(t_grid)))\n",
    "    xi_grid = np.zeros((n_samples, len(t_grid)))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Shifted logistic curve\n",
    "        logistic_01 = 1.0 / (1 + np.exp(-k_samples[i] * (t_grid - t0_samples[i])))\n",
    "        mu_i = lower_bound + (L_samples[i] - lower_bound) * logistic_01\n",
    "        predictions[i] = mu_i\n",
    "\n",
    "        # Heteroskedastic noise for shifted range\n",
    "        variance_shape = np.sqrt((mu_i - lower_bound) * (L_samples[i] - mu_i))\n",
    "        max_variance = (L_samples[i] - lower_bound) / 2.0\n",
    "        noise_factor = variance_shape / np.maximum(\n",
    "            max_variance, 1e-10\n",
    "        )  # Avoid division by zero\n",
    "        xi_grid[i] = 0.01 + xi_base_samples[i] * noise_factor\n",
    "\n",
    "    median_pred = np.percentile(predictions, 50, axis=0)\n",
    "    lower_50_logistic = np.percentile(predictions, 25, axis=0)\n",
    "    upper_50_logistic = np.percentile(predictions, 75, axis=0)\n",
    "    lower_95_logistic = np.percentile(predictions, 2.5, axis=0)\n",
    "    upper_95_logistic = np.percentile(predictions, 97.5, axis=0)\n",
    "\n",
    "    # Prediction intervals with observation noise (vectorized)\n",
    "    from scipy.stats import skewnorm\n",
    "\n",
    "    lower_95_sampling = np.zeros(len(t_grid))\n",
    "    upper_95_sampling = np.zeros(len(t_grid))\n",
    "\n",
    "    for j in range(len(t_grid)):\n",
    "        # Vectorized: one draw per posterior sample\n",
    "        samples = skewnorm.rvs(s_samples, loc=predictions[:, j], scale=xi_grid[:, j])\n",
    "        samples = np.clip(samples, 0, 1)\n",
    "        lower_95_sampling[j] = np.percentile(samples, 2.5)\n",
    "        upper_95_sampling[j] = np.percentile(samples, 97.5)\n",
    "\n",
    "    min_date = frontier_df[\"date\"].min()\n",
    "    dates_grid = [min_date + timedelta(days=int(d)) for d in t_grid]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Add horizontal line for lower bound if > 0\n",
    "    if lower_bound > 0.01:\n",
    "        ax.axhline(\n",
    "            lower_bound,\n",
    "            color=\"gray\",\n",
    "            linestyle=\":\",\n",
    "            alpha=0.5,\n",
    "            linewidth=1.5,\n",
    "            label=f\"Random chance ({lower_bound:.1%})\",\n",
    "        )\n",
    "\n",
    "    ax.fill_between(\n",
    "        dates_grid,\n",
    "        lower_95_sampling,\n",
    "        upper_95_sampling,\n",
    "        alpha=0.1,\n",
    "        color=\"#F18F01\",\n",
    "        label=\"95% prediction interval\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        dates_grid,\n",
    "        lower_95_logistic,\n",
    "        upper_95_logistic,\n",
    "        alpha=0.2,\n",
    "        color=\"#2E86AB\",\n",
    "        label=\"95% CI (logistic)\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        dates_grid,\n",
    "        lower_50_logistic,\n",
    "        upper_50_logistic,\n",
    "        alpha=0.3,\n",
    "        color=\"#2E86AB\",\n",
    "        label=\"50% CI (logistic)\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        dates_grid,\n",
    "        median_pred,\n",
    "        \"-\",\n",
    "        linewidth=2,\n",
    "        color=\"#2E86AB\",\n",
    "        label=\"Median prediction\",\n",
    "    )\n",
    "\n",
    "    if top_n == 1:\n",
    "        ax.plot(\n",
    "            frontier_df[\"date\"],\n",
    "            frontier_df[\"score\"],\n",
    "            \"o\",\n",
    "            markersize=8,\n",
    "            color=\"#A23B72\",\n",
    "            label=\"Observed frontier\",\n",
    "            zorder=10,\n",
    "        )\n",
    "    else:\n",
    "        colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, top_n))\n",
    "        for rank in range(1, top_n + 1):\n",
    "            rank_data = frontier_df[frontier_df[\"rank\"] == rank]\n",
    "            if not rank_data.empty:\n",
    "                ax.plot(\n",
    "                    rank_data[\"date\"],\n",
    "                    rank_data[\"score\"],\n",
    "                    \"o\",\n",
    "                    markersize=10 - (rank - 1) * 1.0,\n",
    "                    color=colors[rank - 1],\n",
    "                    label=f\"Top-{rank} at release\",\n",
    "                    alpha=0.8,\n",
    "                    zorder=10 - rank,\n",
    "                )\n",
    "\n",
    "    last_date = frontier_df[\"date\"].max()\n",
    "    ax.axvline(last_date, color=\"gray\", linestyle=\"--\", alpha=0.5, linewidth=1)\n",
    "    ax.text(\n",
    "        last_date,\n",
    "        ax.get_ylim()[0] + 0.05,\n",
    "        \"Last obs\",\n",
    "        rotation=90,\n",
    "        verticalalignment=\"bottom\",\n",
    "        fontsize=9,\n",
    "        color=\"gray\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    title_suffix = \" (Frontier, Joint)\" if top_n == 1 else f\" (Top-{top_n}, Joint)\"\n",
    "    ax.set_title(\n",
    "        f\"Logistic Growth Forecast: {task_name}{title_suffix}\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"lower right\", fontsize=9)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "    import matplotlib.dates as mdates\n",
    "\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    safe_task_name = task_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "    plot_path = os.path.join(\n",
    "        save_dir, f\"{safe_task_name}_{forecast_type}_top{top_n}_forecast.png\"\n",
    "    )\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    if os.path.exists(\n",
    "        plot_path\n",
    "    ):  # Remove existing file to ensure correct case on macOS\n",
    "        os.remove(plot_path)\n",
    "    print(f\"Saved plot to: {plot_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    title_text = (\n",
    "        f\"FORECAST SUMMARY: {task_name} (Joint Model, Top-{top_n})\"\n",
    "        if top_n > 1\n",
    "        else f\"FORECAST SUMMARY: {task_name} (Joint Model, Frontier)\"\n",
    "    )\n",
    "    print(title_text)\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Data points: {len(frontier_df)}\")\n",
    "    print(f\"Unique models: {frontier_df['model_id'].nunique()}\")\n",
    "    print(f\"Lower asymptote (random chance): {lower_bound:.3f}\")\n",
    "    print(f\"Current best score: {frontier_df['score'].max():.3f}\")\n",
    "    print(\n",
    "        f\"Predicted upper asymptote (L): {np.median(L_samples):.3f} [{np.percentile(L_samples, 2.5):.3f}, {np.percentile(L_samples, 97.5):.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Growth rate (k): {np.median(k_samples):.4f} [{np.percentile(k_samples, 2.5):.4f}, {np.percentile(k_samples, 97.5):.4f}]\"\n",
    "    )\n",
    "    print(f\"Inflection point (t0): {np.median(t0_samples):.0f} days\")\n",
    "\n",
    "\n",
    "def plot_joint_hyperparameters(idata, task_names, save_dir=\"Images\"):\n",
    "    \"\"\"\n",
    "    Plot the learned hyperparameter distributions.\n",
    "\n",
    "    Args:\n",
    "        idata: InferenceData from joint model\n",
    "        task_names: list of task names\n",
    "        save_dir: directory to save plots\n",
    "    \"\"\"\n",
    "    posterior = idata.posterior\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # L hyperparameters\n",
    "    ax = axes[0, 0]\n",
    "    L_mu_samples = posterior[\"L_mu\"].values.flatten()\n",
    "    L_sigma_samples = posterior[\"L_sigma\"].values.flatten()\n",
    "    ax.hist2d(L_mu_samples, L_sigma_samples, bins=50, cmap=\"Blues\")\n",
    "    ax.set_xlabel(\"L_mu (asymptote mean)\", fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"L_sigma (asymptote std)\", fontweight=\"bold\")\n",
    "    ax.set_title(\"Asymptote Hyperparameters\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # k hyperparameters\n",
    "    ax = axes[0, 1]\n",
    "    k_mu_samples = posterior[\"k_mu\"].values.flatten()\n",
    "    k_sigma_samples = posterior[\"k_sigma\"].values.flatten()\n",
    "    ax.hist2d(k_mu_samples, k_sigma_samples, bins=50, cmap=\"Greens\")\n",
    "    ax.set_xlabel(\"k_mu (growth rate mean)\", fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"k_sigma (growth rate std)\", fontweight=\"bold\")\n",
    "    ax.set_title(\"Growth Rate Hyperparameters\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # xi_base hyperparameters\n",
    "    ax = axes[1, 0]\n",
    "    xi_base_mu_samples = posterior[\"xi_base_mu\"].values.flatten()\n",
    "    xi_base_sigma_samples = posterior[\"xi_base_sigma\"].values.flatten()\n",
    "    ax.hist2d(xi_base_mu_samples, xi_base_sigma_samples, bins=50, cmap=\"Oranges\")\n",
    "    ax.set_xlabel(\"xi_base_mu (noise mean)\", fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"xi_base_sigma (noise std)\", fontweight=\"bold\")\n",
    "    ax.set_title(\"Base Noise Hyperparameters\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # s hyperparameters\n",
    "    ax = axes[1, 1]\n",
    "    s_mu_samples = posterior[\"s_mu\"].values.flatten()\n",
    "    s_sigma_samples = posterior[\"s_sigma\"].values.flatten()\n",
    "    ax.hist2d(s_mu_samples, s_sigma_samples, bins=50, cmap=\"Reds\")\n",
    "    ax.set_xlabel(\"s_mu (skewness mean)\", fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"s_sigma (skewness std)\", fontweight=\"bold\")\n",
    "    ax.set_title(\"Skewness Hyperparameters\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_path = os.path.join(save_dir, \"0_joint_hyperparameters.png\")\n",
    "    if os.path.exists(\n",
    "        plot_path\n",
    "    ):  # Remove existing file to ensure correct case on macOS\n",
    "        os.remove(plot_path)\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved hyperparameter plot to: {plot_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"JOINT HYPERPARAMETER SUMMARY\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Number of benchmarks: {len(task_names)}\")\n",
    "    print(f\"\\nAsymptote (L):\")\n",
    "    print(\n",
    "        f\"  L_mu: {np.median(L_mu_samples):.3f} [{np.percentile(L_mu_samples, 2.5):.3f}, {np.percentile(L_mu_samples, 97.5):.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  L_sigma: {np.median(L_sigma_samples):.3f} [{np.percentile(L_sigma_samples, 2.5):.3f}, {np.percentile(L_sigma_samples, 97.5):.3f}]\"\n",
    "    )\n",
    "    print(f\"\\nGrowth rate (k):\")\n",
    "    print(\n",
    "        f\"  k_mu: {np.median(k_mu_samples):.4f} [{np.percentile(k_mu_samples, 2.5):.4f}, {np.percentile(k_mu_samples, 97.5):.4f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  k_sigma: {np.median(k_sigma_samples):.4f} [{np.percentile(k_sigma_samples, 2.5):.4f}, {np.percentile(k_sigma_samples, 97.5):.4f}]\"\n",
    "    )\n",
    "    print(f\"\\nBase noise (xi_base):\")\n",
    "    print(\n",
    "        f\"  xi_base_mu: {np.median(xi_base_mu_samples):.3f} [{np.percentile(xi_base_mu_samples, 2.5):.3f}, {np.percentile(xi_base_mu_samples, 97.5):.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  xi_base_sigma: {np.median(xi_base_sigma_samples):.3f} [{np.percentile(xi_base_sigma_samples, 2.5):.3f}, {np.percentile(xi_base_sigma_samples, 97.5):.3f}]\"\n",
    "    )\n",
    "    print(f\"\\nSkewness (s):\")\n",
    "    print(\n",
    "        f\"  s_mu: {np.median(s_mu_samples):.2f} [{np.percentile(s_mu_samples, 2.5):.2f}, {np.percentile(s_mu_samples, 97.5):.2f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  s_sigma: {np.median(s_sigma_samples):.2f} [{np.percentile(s_sigma_samples, 2.5):.2f}, {np.percentile(s_sigma_samples, 97.5):.2f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab976a10",
   "metadata": {},
   "source": [
    "### Internal benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION: Fit joint model to all internal benchmarks\n",
    "# ============================================================================\n",
    "\n",
    "# Select benchmarks with sufficient data\n",
    "benchmark_dict = {}\n",
    "for task_name, data in internal_matrices.items():\n",
    "    df_long = data[\"df_long\"]\n",
    "    if len(df_long) >= 3:  # Minimum observations\n",
    "        benchmark_dict[task_name] = df_long\n",
    "\n",
    "print(f\"Fitting joint model with {len(benchmark_dict)} internal benchmarks\")\n",
    "\n",
    "# Fit joint model\n",
    "idata_joint, frontier_dfs, model_joint = fit_logistic_joint_hyperparameters(\n",
    "    benchmark_dict,\n",
    "    n_samples=2000,\n",
    "    n_tune=1000,\n",
    "    top_n=3,\n",
    "    forecast_type=\"joint_hyperparameters_internalOnly\",\n",
    "    lower_bounds_dict=lower_bounds_dict,\n",
    ")\n",
    "\n",
    "# Plot learned hyperparameters\n",
    "plot_joint_hyperparameters(idata_joint, list(benchmark_dict.keys()))\n",
    "\n",
    "# Print MCMC diagnostics\n",
    "print(\"\\nJoint Model MCMC Diagnostics:\")\n",
    "print(\n",
    "    az.summary(\n",
    "        idata_joint,\n",
    "        var_names=[\n",
    "            \"L_mu\",\n",
    "            \"L_sigma\",\n",
    "            \"k_mu\",\n",
    "            \"k_sigma\",\n",
    "            \"xi_base_mu\",\n",
    "            \"xi_base_sigma\",\n",
    "            \"s_mu\",\n",
    "            \"s_sigma\",\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT FORECASTS FOR INDIVIDUAL BENCHMARKS\n",
    "# ============================================================================\n",
    "\n",
    "for task_idx, (task_name, frontier_df) in enumerate(frontier_dfs.items()):\n",
    "    print(f\"\\nPlotting: {task_name}\")\n",
    "\n",
    "    # Get lower bound for this benchmark\n",
    "    lower_bound = 0.0\n",
    "    if lower_bounds_dict and task_name in lower_bounds_dict:\n",
    "        lb = lower_bounds_dict[task_name]\n",
    "        if not pd.isna(lb):\n",
    "            lower_bound = lb\n",
    "\n",
    "    plot_logistic_fit_from_joint(\n",
    "        idata_joint,\n",
    "        frontier_df,\n",
    "        task_name,\n",
    "        task_idx,\n",
    "        forecast_days=1523,\n",
    "        top_n=3,\n",
    "        forecast_type=\"joint_hyperparameters\",\n",
    "        lower_bound=lower_bound,\n",
    "    )\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"Successfully fit joint model with {len(benchmark_dict)} benchmarks\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694411a7",
   "metadata": {},
   "source": [
    "### All benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cec9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION: Fit joint model to ALL benchmarks (internal + external)\n",
    "# ============================================================================\n",
    "\n",
    "# Combine all benchmarks with sufficient data\n",
    "benchmark_dict_all = {}\n",
    "\n",
    "# Add internal benchmarks\n",
    "for task_name, data in internal_matrices.items():\n",
    "    df_long = data[\"df_long\"]\n",
    "    if len(df_long) >= 3:  # Minimum observations\n",
    "        benchmark_dict_all[f\"{task_name}\"] = df_long\n",
    "\n",
    "# Add external benchmarks\n",
    "for task_name, data in external_matrices.items():\n",
    "    df_long = data[\"df_long\"]\n",
    "    if len(df_long) >= 3:  # Minimum observations\n",
    "        benchmark_dict_all[f\"{task_name}\"] = df_long\n",
    "\n",
    "# Fit joint model\n",
    "idata_joint_all, frontier_dfs_all, model_joint_all = fit_logistic_joint_hyperparameters(\n",
    "    benchmark_dict_all,\n",
    "    n_samples=2000,\n",
    "    n_tune=1000,\n",
    "    top_n=3,\n",
    "    forecast_type=\"joint_hyperparameters_all\",\n",
    "    lower_bounds_dict=lower_bounds_dict,\n",
    ")\n",
    "\n",
    "# Plot learned hyperparameters\n",
    "plot_joint_hyperparameters(idata_joint_all, list(benchmark_dict_all.keys()))\n",
    "\n",
    "# Print MCMC diagnostics\n",
    "print(\"\\nJoint Model (All Benchmarks) MCMC Diagnostics:\")\n",
    "print(\n",
    "    az.summary(\n",
    "        idata_joint_all,\n",
    "        var_names=[\n",
    "            \"L_mu\",\n",
    "            \"L_sigma\",\n",
    "            \"k_mu\",\n",
    "            \"k_sigma\",\n",
    "            \"xi_base_mu\",\n",
    "            \"xi_base_sigma\",\n",
    "            \"s_mu\",\n",
    "            \"s_sigma\",\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2231d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT FORECASTS FOR INDIVIDUAL BENCHMARKS (ALL)\n",
    "# ============================================================================\n",
    "\n",
    "for task_idx, (task_name, frontier_df) in enumerate(frontier_dfs_all.items()):\n",
    "    print(f\"\\nPlotting: {task_name}\")\n",
    "\n",
    "    # Get lower bound for this benchmark\n",
    "    lower_bound = 0.0\n",
    "    if lower_bounds_dict and task_name in lower_bounds_dict:\n",
    "        lb = lower_bounds_dict[task_name]\n",
    "        if not pd.isna(lb):\n",
    "            lower_bound = lb\n",
    "\n",
    "    plot_logistic_fit_from_joint(\n",
    "        idata_joint_all,\n",
    "        frontier_df,\n",
    "        task_name,\n",
    "        task_idx,\n",
    "        forecast_days=1523,\n",
    "        top_n=3,\n",
    "        forecast_type=\"joint_hyperparameters_all\",\n",
    "        lower_bound=lower_bound,\n",
    "    )\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"Successfully fit joint model with {len(benchmark_dict_all)} benchmarks\")\n",
    "print(f\"  - Internal: {sum(1 for k in frontier_dfs_all if k.startswith('internal_'))}\")\n",
    "print(f\"  - External: {sum(1 for k in frontier_dfs_all if k.startswith('external_'))}\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a7139",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9787736",
   "metadata": {},
   "source": [
    "## Gamma distribution tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f50559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma  # Import gamma function from scipy\n",
    "\n",
    "\n",
    "def gamma_params_from_mu_sigma(mu, sigma):\n",
    "    \"\"\"Convert from PyMC (mu, sigma) to (alpha, beta) parameterization\"\"\"\n",
    "    alpha = (mu / sigma) ** 2\n",
    "    beta = mu / (sigma**2)\n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "def gamma_pdf(x, mu, sigma):\n",
    "    \"\"\"Gamma PDF using PyMC parameterization\"\"\"\n",
    "    alpha, beta = gamma_params_from_mu_sigma(mu, sigma)\n",
    "    return (beta**alpha) * (x ** (alpha - 1)) * np.exp(-beta * x) / gamma(alpha)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "mu = 0.1\n",
    "sigmas = [0.06, 0.07, 0.08]  # different standard deviations\n",
    "x = np.linspace(0, 0.3, 1000)\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot each distribution\n",
    "colors = [\"#2E86AB\", \"#A23B72\", \"#F18F01\", \"#C73E1D\"]\n",
    "for sigma, color in zip(sigmas, colors):\n",
    "    plt.plot(x, gamma_pdf(x, mu, sigma), \"-\", color=color, lw=2, label=f\"σ={sigma:.3f}\")\n",
    "\n",
    "    # Print implied parameters\n",
    "    alpha, beta = gamma_params_from_mu_sigma(mu, sigma)\n",
    "    print(f\"σ={sigma:.3f}: α={alpha:.2f}, β={beta:.2f}\")\n",
    "\n",
    "# Add vertical line for mean\n",
    "plt.axvline(mu, color=\"black\", linestyle=\"--\", alpha=0.5, label=\"Mean (μ)\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Gamma Distribution (PyMC parameterization) - Fixed μ={mu}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "alpha, beta = gamma_params_from_mu_sigma(mu, sigma)\n",
    "print(f\"Equivalent standard parameters: alpha={alpha:.2f}, beta={beta:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
